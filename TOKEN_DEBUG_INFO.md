# è¯¦ç»†Tokenè°ƒè¯•ä¿¡æ¯è¾“å‡º

## ğŸ” æ–°å¢çš„è°ƒè¯•åŠŸèƒ½

ä¸ºäº†å¸®åŠ©è¯Šæ–­å•è¯åˆå¹¶é—®é¢˜ï¼Œæˆ‘æ·»åŠ äº†ä»¥ä¸‹è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯è¾“å‡ºï¼š

### 1. åŸæ–‡å’ŒTokenè¯¦ç»†åˆ†æ

#### åŸæ–‡ä¿¡æ¯
```
ğŸ”¤ Starting word matching process (sequential, non-window based):
  - Original text: "Hello world this is a test"
  - Original text length: 26
  - Text character codes: [72,101,108,108,111,32,119,111,114,108,100,32,116,104,105,115,32,105,115,32,97,32,116,101,115,116]
```

#### Tokenè¯¦ç»†åˆ†æ
```
ğŸ“‹ Detailed token analysis:
  Token[0]: "Hello" | Length:5 | Whitespace:false | HasWord:true | CharCodes:[72,101,108,108,111]
  Token[1]: " " | Length:1 | Whitespace:true | HasWord:false | CharCodes:[32]
  Token[2]: "world" | Length:5 | Whitespace:false | HasWord:true | CharCodes:[119,111,114,108,100]
  Token[3]: " " | Length:1 | Whitespace:true | HasWord:false | CharCodes:[32]
  ...
```

### 2. è·¨TokenåŒ¹é…è¯¦ç»†ä¿¡æ¯

#### åŒ¹é…å°è¯•è¯¦æƒ…
```
  - Trying 3-token combine [0-3): "Hello world" (hello world) vs "Hello" (hello)
    * Combine tokens: [0]="Hello", [1]=" ", [2]="world"
    * Combined raw: "Hello world"
    * Combined normalized: "hello world"
    * Target word normalized: "hello"
  - âŒ Skipping combine: combined text "Hello world" has space but LLM word "Hello" doesn't
```

### 3. æœ€ç»ˆç»“æœåˆ†æ

#### ç»“æœTokenå¯¹æ¯”
```
ğŸ“Š Final result tokens analysis:
  Result[0]: "<ruby>Hello</ruby>" | Original:"Hello" | IsOriginal:false | WasProcessed:true
  Result[1]: " " | Original:" " | IsOriginal:true | WasProcessed:false
  Result[2]: "world" | Original:"world" | IsOriginal:true | WasProcessed:false
  Result[3]: " " | Original:" " | IsOriginal:true | WasProcessed:false
  ...
```

## ğŸ¯ è°ƒè¯•ä¿¡æ¯çš„ç”¨é€”

### æ£€æŸ¥TokenåŒ–é—®é¢˜
- **Character codes**: æ˜¾ç¤ºæ¯ä¸ªå­—ç¬¦çš„Unicodeç¼–ç ï¼Œå¸®åŠ©è¯†åˆ«éšè—å­—ç¬¦
- **Tokenè¯¦æƒ…**: æ˜¾ç¤ºæ¯ä¸ªtokençš„ç±»å‹ï¼ˆç©ºæ ¼ã€å•è¯ç­‰ï¼‰
- **é•¿åº¦ä¿¡æ¯**: æ£€æŸ¥tokenæ˜¯å¦è¢«æ„å¤–åˆ†å‰²æˆ–åˆå¹¶

### æ£€æŸ¥åŒ¹é…é€»è¾‘
- **Combine tokens**: æ˜¾ç¤ºå‚ä¸ç»„åˆçš„å…·ä½“token
- **Combined raw vs normalized**: å¯¹æ¯”åŸå§‹ç»„åˆå’Œæ ‡å‡†åŒ–åçš„ç»“æœ
- **è·³è¿‡åŸå› **: æ˜ç¡®æ˜¾ç¤ºä¸ºä»€ä¹ˆæŸä¸ªç»„åˆè¢«è·³è¿‡

### æ£€æŸ¥æœ€ç»ˆç»“æœ
- **IsOriginal**: æ£€æŸ¥tokenæ˜¯å¦è¢«ä¿®æ”¹
- **WasProcessed**: æ£€æŸ¥tokenæ˜¯å¦è¢«æ ‡è®°ä¸ºå·²å¤„ç†
- **å¯¹æ¯”**: åŸå§‹token vs æœ€ç»ˆresult token

## ğŸš¨ å¯èƒ½å‘ç°çš„é—®é¢˜

### 1. TokenåŒ–å¼‚å¸¸
```
Token[5]: "hel lo" | Length:6 | Whitespace:false | HasWord:true
```
å¦‚æœçœ‹åˆ°è¿™æ ·çš„tokenï¼Œè¯´æ˜tokenizationæœ‰é—®é¢˜ã€‚

### 2. æ„å¤–çš„è·¨TokenåŒ¹é…
```
* Combine tokens: [5]="Hello", [6]=" ", [7]="world"
* Combined normalized: "hello world"
* Target word normalized: "hello"
âœ… MULTI-TOKEN MATCH! (è¿™æ˜¯é”™è¯¯çš„)
```

### 3. Tokenè¢«æ„å¤–ä¿®æ”¹
```
Result[5]: "<ruby>Hello world</ruby>" | Original:"Hello" | IsOriginal:false | WasProcessed:true
Result[6]: " " | Original:" " | IsOriginal:true | WasProcessed:true
Result[7]: "world" | Original:"world" | IsOriginal:true | WasProcessed:true
```
å¦‚æœçœ‹åˆ°è¿™æ ·çš„ç»“æœï¼Œè¯´æ˜å•è¯è¢«é”™è¯¯åˆå¹¶äº†ã€‚

## ğŸ“‹ ä½¿ç”¨æ–¹æ³•

1. **æ‰“å¼€æµè§ˆå™¨å¼€å‘è€…å·¥å…·**
2. **åˆ‡æ¢åˆ°Consoleæ ‡ç­¾**
3. **è§¦å‘å•è¯æ³¨é‡ŠåŠŸèƒ½**
4. **æŸ¥çœ‹è¯¦ç»†çš„è°ƒè¯•è¾“å‡º**
5. **é‡ç‚¹å…³æ³¨**ï¼š
   - TokenåŒ–æ˜¯å¦æ­£ç¡®
   - è·¨tokenåŒ¹é…çš„é€»è¾‘
   - æœ€ç»ˆç»“æœçš„å¯¹æ¯”

## ğŸ”§ é—®é¢˜å®šä½æµç¨‹

1. **æ£€æŸ¥åŸæ–‡**: ç¡®è®¤åŸæ–‡æœ¬èº«æ²¡æœ‰é—®é¢˜
2. **æ£€æŸ¥TokenåŒ–**: æŸ¥çœ‹tokensæ˜¯å¦æ­£ç¡®åˆ†å‰²
3. **æ£€æŸ¥åŒ¹é…è¿‡ç¨‹**: çœ‹å“ªäº›tokenè¢«ç»„åˆï¼Œä¸ºä»€ä¹ˆ
4. **æ£€æŸ¥æœ€ç»ˆç»“æœ**: å¯¹æ¯”original vs resultï¼Œæ‰¾å‡ºè¢«é”™è¯¯ä¿®æ”¹çš„token

è¿™äº›è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯åº”è¯¥èƒ½å¸®åŠ©æˆ‘ä»¬å¿«é€Ÿå®šä½å•è¯åˆå¹¶é—®é¢˜çš„æ ¹æœ¬åŸå› ï¼ğŸ¯
